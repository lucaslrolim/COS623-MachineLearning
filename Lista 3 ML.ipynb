{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning COS-623 - Terceiro Trimestre de 2017\n",
    "## Terceira e Quarta Listas de Exercı́cios (Graduação e Pós-Graduação)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np # manipulação de matrizes\n",
    "import pandas as pd # Manipulação de datasets\n",
    "import matplotlib.pyplot as plt # Para plotagem\n",
    "import seaborn as sns # Coloração melhor nas plotagens\n",
    "import scipy.stats as stats # Normalizações, cálculos de densidade de probabilidade, etc\n",
    "import sklearn # Implementação de modelos preditivos e de classificação\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Lendo o dataset e separando os dados em 1000 dados de treino e 172 dados de teste\n",
    "df = pd.read_csv(\"Dados-medicos.txt\",sep=\" \")\n",
    "df = df.drop('Unnamed: 1', 1) ## removendo coluna gerado errôneamentod devido à formatação dos dados\n",
    "df = df.drop('Unnamed: 2', 1) ## removendo coluna gerado errôneamentod devido à formatação dos dados\n",
    "\n",
    "train = df.sample(frac = 0.85324232082,random_state=200)\n",
    "test  = df.drop(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de apoio para primeira questão\n",
    "\n",
    "Vamos definir uma função para executar o modelo de Regressão Linear, bem como analisar seu desempenho ao manipular as variáveis de entrada X e também plotar seu resultado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression ## Modelo de regressão linear\n",
    "from sklearn.preprocessing import PolynomialFeatures ## Geração de features para modelos\n",
    "\n",
    "def do_rmse(y,y_predicted):\n",
    "    return np.sqrt(np.mean((y - y_predicted) **2 ))\n",
    "\n",
    "def negativeLogLikelihood(testDataset,variance,y,y_predicted):\n",
    "    return -(len(testDataset)/2)*np.log(2*np.pi*variance) - (1/(2*variance))* np.sum((y - y_predicted) **2 )\n",
    "\n",
    "def linearRegression2(train,test,variables,target,polyDegree, toPlot = False, plotedVariables = None):\n",
    "    # Vamos criar trainFeatures e testFeatures e aplicar sobre eles as transformações dados pelas base functions\n",
    "    # E.g., Para duas features a e b, para um polinomio de grau 2, as funções base serão:\n",
    "    # [1, a, b, a^2, ab, b^2]\n",
    "\n",
    "    trainData = train[variables]\n",
    "    trainFeatures = trainData.drop(target, axis = 1)\n",
    "\n",
    "    testData = test[variables]\n",
    "    testFeatures = testData.drop(target, axis = 1)\n",
    "\n",
    "    polyDegree = 4\n",
    "\n",
    "    # executa para todos os graus de 1 até polyDegree\n",
    "    for i in range (1,polyDegree+1):\n",
    "        poly = PolynomialFeatures(degree=i)\n",
    "        X = poly.fit_transform(trainFeatures)\n",
    "        test_X = poly.fit_transform(testFeatures)\n",
    "\n",
    "        X = pd.DataFrame(data=X[0:,0:],index=X[0:,0])\n",
    "        test_X = pd.DataFrame(data=test_X[0:,0:],index=test_X[0:,0]) \n",
    "\n",
    "        lm = LinearRegression()\n",
    "        lm.fit(X,trainData.VO2_medido_máximo)\n",
    "        print(pd.DataFrame(list(zip(X.columns,lm.coef_)),columns = ['features','w']))\n",
    "        rmse =  np.sqrt(np.mean( (test.VO2_medido_máximo - lm.predict(test_X) ) **2 ))\n",
    "        print(\"O RMSE com polinômio de grau %i foi de %f\" % (i,rmse)) \n",
    "        var = test[['VO2_medido_máximo']].var()\n",
    "        nll = -(len(test)/2)*np.log(2*np.pi*var) - (1/(2*var))* np.sum( (test.VO2_medido_máximo - lm.predict(test_X) ) **2 )\n",
    "        print(\"O NLL com polinômio de grau %i foi de %f \\n\" % (i,nll)) \n",
    "        \n",
    "    if(toPlot):\n",
    "        # plots graph\n",
    "        y = train[['VO2_medido_máximo']].values\n",
    "        x = train[plotedVariables].values\n",
    "        plt.scatter(x,y)\n",
    "        plt.plot(x, lm.predict(poly.fit_transform(x)), color='blue', linewidth=3)\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.savefig(\"test.png\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1\n",
    "\n",
    "### 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "linearRegression2(train,test,['Carga_Final','VO2_medido_máximo'],['VO2_medido_máximo'],4, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "linearRegression2(\n",
    "    train,\n",
    "    test,\n",
    "    ['Peso', 'Carga_Final','VO2_medido_máximo'],\n",
    "    ['VO2_medido_máximo'],\n",
    "    4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Questão 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "linearRegression2(\n",
    "    train,\n",
    "    test,\n",
    "    ['IDADE', 'Peso', 'Carga_Final','VO2_medido_máximo'],\n",
    "    ['VO2_medido_máximo'],\n",
    "    4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questao 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 \n",
    "\n",
    "Referências:\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Multivariate_normal_distribution\n",
    "- https://stackoverflow.com/questions/38698277/plot-normal-distribution-in-3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Parâmetros da Gaussiana\n",
    "\n",
    "var_carga = train[['Carga_Final']].var().values[0]\n",
    "mean_carga = train[['Carga_Final']].mean().values[0]\n",
    "\n",
    "var_vo2 = train[['VO2_medido_máximo']].var().values[0]\n",
    "mean_vo2 = train[['VO2_medido_máximo']].mean().values[0]\n",
    "\n",
    "## Criação de Grid para plotagem da Gaussiana multivariada \n",
    "\n",
    "x = np.linspace(train[['Carga_Final']].min(),train[['Carga_Final']].max(),500)\n",
    "y = np.linspace(train[['VO2_medido_máximo']].min(),train[['VO2_medido_máximo']].max(),500)\n",
    "\n",
    "X, Y = np.meshgrid(x,y)\n",
    "pos = np.empty(X.shape + (2,))\n",
    "pos[:, :, 0] = X; pos[:, :, 1] = Y\n",
    "rv = multivariate_normal([mean_carga, mean_vo2], [[var_carga, 0], [0, var_vo2]])\n",
    "\n",
    "# Plotagem 3D\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(X, Y, rv.pdf(pos),cmap='viridis',linewidth=0)\n",
    "ax.set_xlabel('Carga_Final')\n",
    "ax.set_ylabel('VO2_medido_máximo')\n",
    "ax.set_zlabel('Densidade de Probabilidade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "## Questão 3\n",
    "### Questão 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parâmetros da Gaussiana\n",
    "train = train[['Carga_Final']].var().values[0]\n",
    "mean_carga = train[['Carga_Final']].mean().values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onde $\\boldsymbol{x} = [x_1, x_2, .., x_D]$\n",
    ", pela independência entre as features assumida no modelo Naive Bayes, podemos calcular a probabilidade da classe como:\n",
    "$$ p(h = c \\mid \\boldsymbol{x}, \\theta) \\propto p(h=c \\mid \\theta) \\prod_{i=1}^{D} p(x_i \\mid h=c, \\theta)  $$\n",
    "$$ posterior \\propto prior * likelihood $$\n",
    "A prior $p(h=c \\mid \\theta)$ que pode ser genarada como o número de amostras pertencentes a classe $c$ dividido pelo número total de amostras.\n",
    "\n",
    "A likelihood, portanto, é baseado no modelo Gaussiano, já presente no enunciado da questão."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
