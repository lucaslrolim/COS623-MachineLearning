{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning COS-623 - Terceiro Trimestre de 2017\n",
    "## Terceira e Quarta Listas de Exercı́cios (Graduação e Pós-Graduação)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # manipulação de matrizes\n",
    "import pandas as pd # Manipulação de datasets\n",
    "import matplotlib.pyplot as plt # Para plotagem\n",
    "import seaborn as sns # Coloração melhor nas plotagens\n",
    "import scipy.stats as stats # Normalizações, cálculos de densidade de probabilidade, etc\n",
    "import sklearn # Implementação de modelos preditivos e de classificação\n",
    "import scipy \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Lendo o dataset e separando os dados em 1000 dados de treino e 172 dados de teste\n",
    "df = pd.read_csv(\"Dados-medicos.txt\",sep=\" \")\n",
    "df = df.drop('Unnamed: 1', 1) ## removendo coluna gerado errôneamentod devido à formatação dos dados\n",
    "df = df.drop('Unnamed: 2', 1) ## removendo coluna gerado errôneamentod devido à formatação dos dados\n",
    "\n",
    "train = df.sample(frac = 0.85324232082,random_state=200)\n",
    "test  = df.drop(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções de apoio para primeira questão\n",
    "\n",
    "Vamos definir uma função para executar o modelo de Regressão Linear, bem como analisar seu desempenho ao manipular as variáveis de entrada X e também plotar seu resultado final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression ## Modelo de regressão linear\n",
    "from sklearn.preprocessing import PolynomialFeatures ## Geração de features para modelos\n",
    "\n",
    "def do_rmse(y,y_predicted):\n",
    "    return np.sqrt(np.mean((y - y_predicted) **2 ))\n",
    "\n",
    "def negativeLogLikelihood(testDataset,variance,y,y_predicted):\n",
    "    return -(len(testDataset)/2)*np.log(2*np.pi*variance) - (1/(2*variance))* np.sum((y - y_predicted) **2 )\n",
    "\n",
    "def linear_regression(train,test,variables,target,polyDegree):\n",
    "    ## Vamos criar X_ e test_ para ser datasets que possuem os valores das nossas variaveis x (carga) elevado a n\n",
    "\n",
    "    data = train[variables]\n",
    "    X_ = data.drop(target, axis = 1)\n",
    "\n",
    "    testData = test[variables]\n",
    "    test_ = testData.drop(target, axis = 1)\n",
    "\n",
    "    polyDegree = 4\n",
    "    poly = PolynomialFeatures(degree=polyDegree)\n",
    "\n",
    "    X_ = poly.fit_transform(X_)\n",
    "\n",
    "    test_ = poly.fit_transform(test_)\n",
    "\n",
    "    X_ = pd.DataFrame(data=X_[0:,0:],index=X_[0:,0])\n",
    "\n",
    "    test_ = pd.DataFrame(data=test_[0:,0:],index=test_[0:,0]) \n",
    "\n",
    "    ## Executando uma regressao polinomial para cada grau de polinomio <= polyDegree\n",
    "    lm = LinearRegression()\n",
    "    for i in range (1,polyDegree+1):\n",
    "        X = X_.iloc[:,0:i+1]\n",
    "        test_X = test_.iloc[:,0:i+1]\n",
    "        lm.fit(X,data.VO2_medido_máximo)\n",
    "        print(pd.DataFrame(list(zip(X.columns,lm.coef_)),columns = ['features','w']))\n",
    "        rmse = do_rmse(test.VO2_medido_máximo,lm.predict(test_X))\n",
    "        print(\"O RMSE com polinômio de grau %i foi de %f\" % (i,rmse)) \n",
    "        var = test[['VO2_medido_máximo']].var().values[0]\n",
    "        nll = negativeLogLikelihood(test,var,test.VO2_medido_máximo,lm.predict(test_X))\n",
    "        print(\"O NLL com polinômio de grau %i foi de %f \\n\" % (i,nll)) \n",
    "\n",
    "    # plots graph\n",
    "    \n",
    "    y = train[['VO2_medido_máximo']].values\n",
    "    x = train[['Carga_Final']].values\n",
    "    plt.scatter(x,y)\n",
    "    plt.plot(x, lm.predict(poly.fit_transform(x)), color='blue', linewidth=3)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"test.png\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1\n",
    "\n",
    "### 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression(train,test,['Carga_Final','VO2_medido_máximo'],['VO2_medido_máximo'],4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusão**:\n",
    "Com o polinômio de grau 4 e apenas um parâmetro carga, fomos capazes de prever o VO2Max com um RMS error de 5.264564. Dado que a média do VO2Max é 29.3080070841, obtemos uma discrepância relativa média de aprox. 18%. Por isto, consideramos que nosso modelo de regressão linear não é satisfatório.\n",
    "\n",
    "### Questão 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos criar trainFeatures e testFeatures e aplicar sobre eles as transformações dados pelas base functions\n",
    "# E.g., Para duas features a e b, para um polinomio de grau 2, as funções base serão:\n",
    "# [1, a, b, a^2, ab, b^2]\n",
    "\n",
    "trainData = train[['Peso', 'Carga_Final','VO2_medido_máximo']]\n",
    "trainFeatures = trainData.drop('VO2_medido_máximo', axis = 1)\n",
    "\n",
    "testData = test[['Peso', 'Carga_Final','VO2_medido_máximo']]\n",
    "testFeatures = testData.drop('VO2_medido_máximo', axis = 1)\n",
    "\n",
    "polyDegree = 4\n",
    "\n",
    "# executa para todos os graus de 1 até polyDegree\n",
    "for i in range (1,polyDegree+1):\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "    X = poly.fit_transform(trainFeatures)\n",
    "    test_X = poly.fit_transform(testFeatures)\n",
    "\n",
    "    X = pd.DataFrame(data=X[0:,0:],index=X[0:,0])\n",
    "    test_X = pd.DataFrame(data=test_X[0:,0:],index=test_X[0:,0]) \n",
    "\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X,trainData.VO2_medido_máximo)\n",
    "    print(pd.DataFrame(list(zip(X.columns,lm.coef_)),columns = ['features','w']))\n",
    "    rmse =  np.sqrt(np.mean( (test.VO2_medido_máximo - lm.predict(test_X) ) **2 ))\n",
    "    print(\"O RMSE com polinômio de grau %i foi de %f\" % (i,rmse)) \n",
    "    var = test[['VO2_medido_máximo']].var()\n",
    "    nll = -(len(test)/2)*np.log(2*np.pi*var) - (1/(2*var))* np.sum( (test.VO2_medido_máximo - lm.predict(test_X) ) **2 )\n",
    "    print(\"O NLL com polinômio de grau %i foi de %f \\n\" % (i,nll)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Conclusão**: Com o polinômio de grau 4 e com dois parâmetros, carga e peso, fomos capazes de prever o VO2Max com um RMS error de 3.536983. Dado que a média do VO2Max é 29.3080070841, obtemos uma discrepância relativa média de aprox. 12%. Por isto, ainda consideramos que nosso modelo de regressão linear não é satisfatório, porém melhora a previsão anterior.\n",
    "\n",
    "### Questão 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identical solution as question 1.2, but including the new feature age\n",
    "trainData = train[['IDADE', 'Peso', 'Carga_Final','VO2_medido_máximo']]\n",
    "trainFeatures = trainData.drop('VO2_medido_máximo', axis = 1)\n",
    "\n",
    "testData = test[['IDADE', 'Peso', 'Carga_Final','VO2_medido_máximo']]\n",
    "testFeatures = testData.drop('VO2_medido_máximo', axis = 1)\n",
    "\n",
    "polyDegree = 4\n",
    "\n",
    "# executa para todos os graus de 1 até polyDegree\n",
    "for i in range (1,polyDegree+1):\n",
    "    poly = PolynomialFeatures(degree=i)\n",
    "    X = poly.fit_transform(trainFeatures)\n",
    "    test_X = poly.fit_transform(testFeatures)\n",
    "\n",
    "    X = pd.DataFrame(data=X[0:,0:],index=X[0:,0])\n",
    "    test_X = pd.DataFrame(data=test_X[0:,0:],index=test_X[0:,0]) \n",
    "\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X,trainData.VO2_medido_máximo)\n",
    "    print(pd.DataFrame(list(zip(X.columns,lm.coef_)),columns = ['features','w']))\n",
    "    rmse =  np.sqrt(np.mean( (test.VO2_medido_máximo - lm.predict(test_X) ) **2 ))\n",
    "    print(\"O RMSE com polinômio de grau %i foi de %f\" % (i,rmse)) \n",
    "    var = test[['VO2_medido_máximo']].var()\n",
    "    nll = -(len(test)/2)*np.log(2*np.pi*var) - (1/(2*var))* np.sum( (test.VO2_medido_máximo - lm.predict(test_X) ) **2 )\n",
    "    print(\"O NLL com polinômio de grau %i foi de %f \\n\" % (i,nll)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusão**: Com o polinômio de grau 4 e com três parâmetros, carga e peso e idade, fomos capazes de prever o VO2Max com um RMS error de 3.536453, muito próximo da previsão anterior, mantendo a discrepância relativa anterior de aprox. 12%. Por isto, consideramos que nosso modelo de regressão linear não é satisfatório e a inclusão da idade não mudou a previsão do VO2Max."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acsm_formula(w,peso):\n",
    "    return round((w*11.4+260+peso*3.5)/peso,3)\n",
    "\n",
    "for i in range(len(test)):\n",
    "    acsm.append(acsm_formula(test.Carga_Final.values[i],\n",
    "                            test.Peso.values[i]))\n",
    "acsm_rmse = do_rmse(test[['VO2_medido_máximo']].values,acsm)\n",
    "acsm_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusão**\n",
    "Através da regressão linear na questão 1.2 obtivemos um RMSE = 3.536983, enquanto a fórmula do American College of Sports\n",
    "Medicine obteve RMSE = 12.99829652090186, portanto podemos afirmar que\n",
    "o desempenho de nossa regressão foi superior.\n",
    "\n",
    "Ao adicionar aos parâmentros a idade, a regressão obteve uma melhora desprezível, diminuindo o RMSE em 0.0002%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questao 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 \n",
    "\n",
    "Referências:\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Multivariate_normal_distribution\n",
    "- https://stackoverflow.com/questions/38698277/plot-normal-distribution-in-3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Parâmetros da Gaussiana\n",
    "my_data = train[['Carga_Final','VO2_medido_máximo']]\n",
    "cov = my_data.cov().as_matrix()\n",
    "\n",
    "mean_carga = train[['Carga_Final']].mean().values[0]\n",
    "mean_vo2 = train[['VO2_medido_máximo']].mean().values[0]\n",
    "\n",
    "## Criação de Grid para plotagem da Gaussiana multivariada \n",
    "\n",
    "x = np.linspace(train[['Carga_Final']].min(),train[['Carga_Final']].max(),500)\n",
    "y = np.linspace(train[['VO2_medido_máximo']].min(),train[['VO2_medido_máximo']].max(),500)\n",
    "\n",
    "X, Y = np.meshgrid(x,y)\n",
    "pos = np.empty(X.shape + (2,))\n",
    "pos[:, :, 0] = X; pos[:, :, 1] = Y\n",
    "rv = multivariate_normal([mean_carga, mean_vo2],cov)\n",
    "\n",
    "# Plotagem 3D\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.plot_surface(X, Y, rv.pdf(pos),cmap='viridis',linewidth=0)\n",
    "ax.set_xlabel('Carga_Final')\n",
    "ax.set_ylabel('VO2_medido_máximo')\n",
    "ax.set_zlabel('Densidade de Probabilidade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que a variável *V02* é contínua, a maneira mais adequada para resolver esse problema é primeiro integrando nossa Gaussiana no eixo do **Peso** e da **Carga** de acordo com os valores dados, depois definindo faixas de intervalo em V02 e integrando  para encontrar qual obtém maior probabilidade.\n",
    "\n",
    "Devido a limitações de capacidade de processamento, neste trabalho nós retornaremos apenas uma aproximação do valor mais provável de VO2, sem a distribuição de probabilidade dos demais valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Cria um array com os valores que seriam previstos pela formula da American College of Sports and Medicine nos dados de teste\n",
    "acsm = []\n",
    "\n",
    "def acsm_formula(w,peso):\n",
    "    return round((w*11.4+260+peso*3.5)/peso,3)\n",
    "\n",
    "for i in range(len(test)):\n",
    "    acsm.append(acsm_formula(test.Carga_Final.values[i],\n",
    "                            test.Peso.values[i]))\n",
    "acsm_rmse = do_rmse(test[['VO2_medido_máximo']].values,acsm)\n",
    "acsm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_prob(n):\n",
    "    predict_v02 = []\n",
    "    for j in range(len(test)):\n",
    "        max_prob = 0 \n",
    "        max_value = 0\n",
    "        values = np.linspace(test[['VO2_medido_máximo']].min(),test[['VO2_medido_máximo']].max(),10000)\n",
    "        for i in values:\n",
    "            if(n==2):\n",
    "                vo2 = rv2.pdf([test.Carga_Final[0],test.Peso[0],i])\n",
    "            if(n==3):\n",
    "                vo2 = rv2.pdf([test.Carga_Final[0],test.Peso[0],test.IDADE[0],i])\n",
    "            if(vo2 > max_prob):\n",
    "                max_prob = vo2\n",
    "                max_value = i\n",
    "        predict_v02.append(i)\n",
    "    return predict_v02\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_peso = train[['Peso']].mean().values[0]\n",
    "\n",
    "my_data = train[['Carga_Final','VO2_medido_máximo','Peso']]\n",
    "cov = my_data.cov().as_matrix()\n",
    "mu = [mean_carga,mean_peso,mean_vo2]\n",
    "rv2 = multivariate_normal(mu, cov)\n",
    "\n",
    "sample_values =  [[70,94.1],[260,70],[220,100]]\n",
    "\n",
    "\n",
    "for j in range(len(sample_values)):\n",
    "    probs = []\n",
    "    pv = []\n",
    "    max_prob = 0 \n",
    "    max_value = 0\n",
    "    values = np.linspace(test[['VO2_medido_máximo']].min(),test[['VO2_medido_máximo']].max(),10000)\n",
    "    for i in values:\n",
    "        vo2 = rv2.pdf([sample_values[j][0],sample_values[j][1],i])\n",
    "        probs.append(vo2)\n",
    "        pv.append(i)\n",
    "        if(vo2 > max_prob):\n",
    "            max_prob = vo2\n",
    "            max_value = i \n",
    "    print((\"O valor de Vo2 mais provável para o peso %s e a carga %s é: %s e o valor previsto pela ACMS é de %s\") %\n",
    "          (sample_values[j][0],\n",
    "           sample_values[j][1],\n",
    "           round(max_value,3),\n",
    "           acsm_formula(sample_values[j][0],sample_values[j][1])))\n",
    "\n",
    "\n",
    "predict_v02 = estimate_prob(2)\n",
    "\n",
    "\n",
    "result_rmse = do_rmse(test[['VO2_medido_máximo']].values,predict_v02)\n",
    "result_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De modo a mostrar que esse método, mesmo que simplista, consegue estimar o resultado de forma razoável, basta plotarmos como exemplo o gráfico de distribuição de probabilidades para os valores de de carga e peso [220,100]. Vemos que o ponto que previmos *(15.095)* está exatamente no máximo global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(pv, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O RMSE da fórmula do *American College of Sports Medicine* alcançou um RMSE aproximadamente 80% menor do que o encontrado pelo nosso modelo. Como não sabemos como a fórmula foi produzida, podemos especular que parte desse desempenho melhor se deve ao fato da fórmula do ACSM ter sido criado com base em mais dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_idade = train[['IDADE']].mean().values[0]\n",
    "\n",
    "my_data = train[['Carga_Final','VO2_medido_máximo','Peso','IDADE']]\n",
    "cov = my_data.cov().as_matrix()\n",
    "\n",
    "rv2 = multivariate_normal([mean_carga,mean_peso,mean_idade,mean_vo2], cov)\n",
    "\n",
    "sample_values =  [[70,94.1,18],[260,70,30],[220,100,60]]\n",
    "\n",
    "for j in range(len(sample_values)):\n",
    "    probs = []\n",
    "    pv = []\n",
    "    max_prob = 0 \n",
    "    max_value = 0\n",
    "    values = np.linspace(train[['VO2_medido_máximo']].min(),train[['VO2_medido_máximo']].max(),10000)\n",
    "    for i in values:\n",
    "        vo2 = rv2.pdf([sample_values[j][0],sample_values[j][1],sample_values[j][2],i])\n",
    "        probs.append(vo2)\n",
    "        pv.append(i)\n",
    "        if(vo2 > max_prob):\n",
    "            max_prob = vo2\n",
    "            max_value = i \n",
    "    print((\"O valor de Vo2 mais provável para o peso %s,a carga %s e idade %s é: %s e o valor previsto pela ACMS é de %s\") %\n",
    "          (sample_values[j][0],\n",
    "           sample_values[j][1],\n",
    "           sample_values[j][2],\n",
    "           round(max_value,3),\n",
    "           acsm_formula(sample_values[j][0],sample_values[j][1])))\n",
    "    \n",
    "predict_v02 = estimate_prob(3)\n",
    "\n",
    "result_rmse = do_rmse(test[['VO2_medido_máximo']].values,predict_v02)\n",
    "result_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(pv, probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que não houve diferença significativa no modelo ao inserir a idade. a fórmula do ACSM permaneceu com um RMSE por volta de 80% mais baixo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 3\n",
    "### 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "trainingGroups = {}\n",
    "trainingGroups['18_40'] = train.loc[(train['IDADE'] > 18) & (train['IDADE'] <= 40)][['Carga_Final','VO2_medido_máximo']]\n",
    "trainingGroups['40_60'] = train.loc[(train['IDADE'] > 40) & (train['IDADE'] <= 60)][['Carga_Final','VO2_medido_máximo']]\n",
    "trainingGroups['60'] = train.loc[(train['IDADE'] >= 60)][['Carga_Final','VO2_medido_máximo']]\n",
    "\n",
    "groups = ['18_40', '40_60', '60']\n",
    "\n",
    "# Parâmetros das Gaussianas\n",
    "params = {}\n",
    "for group in groups:\n",
    "    params[group] = {}\n",
    "    params[group]['cov'] = trainingGroups[group].cov().as_matrix()\n",
    "    params[group]['mean_carga'] = trainingGroups[group][['Carga_Final']].mean().values[0]\n",
    "    params[group]['mean_vo2'] = trainingGroups[group][['VO2_medido_máximo']].mean().values[0]\n",
    "    \n",
    "## Criação de Grid para plotagem da Gaussiana multivariada \n",
    "x = np.linspace(train[['Carga_Final']].min(),train[['Carga_Final']].max(),500)\n",
    "y = np.linspace(train[['VO2_medido_máximo']].min(),train[['VO2_medido_máximo']].max(),500)\n",
    "X, Y = np.meshgrid(x,y)\n",
    "pos = np.empty(X.shape + (2,))\n",
    "pos[:, :, 0] = X; pos[:, :, 1] = Y\n",
    "\n",
    "# Plotagem 3D\n",
    "for group in groups:\n",
    "    print(group)\n",
    "    rv = multivariate_normal([params[group]['mean_carga'], params[group]['mean_vo2']], params[group]['cov'])\n",
    "    fig = plt.figure(figsize=(9, 9))\n",
    "    ax = fig.gca(projection='3d')\n",
    "    ax.plot_surface(X, Y, rv.pdf(pos),cmap='viridis',linewidth=0)\n",
    "    ax.set_xlabel('Carga_Final')\n",
    "    ax.set_ylabel('VO2_medido_máximo')\n",
    "    ax.set_zlabel('Densidade de Probabilidade')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos perceber pelos plots dos diferentes modelos que o pico a Gaussiana vai se aproximando da origem (0, 0) com o aumento da idade.\n",
    "\n",
    "### Questão 3.2\n",
    "Onde $\\boldsymbol{x} = [x_1, x_2, .., x_D]$\n",
    ", pela independência entre as features assumida no modelo Naive Bayes, podemos calcular a probabilidade da classe como:\n",
    "$$ p(h = c \\mid \\boldsymbol{x}, \\theta) \\propto p(h=c \\mid \\theta) \\prod_{i=1}^{D} p(x_i \\mid h=c, \\theta)  $$\n",
    "$$ posterior \\propto prior * likelihood $$\n",
    "A prior $p(h=c \\mid \\theta)$ que pode ser gerada como o número de amostras pertencentes a classe $c$ dividido pelo número total de amostras.\n",
    "\n",
    "A likelihood, portanto, é baseado no modelo Gaussiano, já presente no enunciado da questão.\n",
    "\n",
    "### Questão 3.3\n",
    "A suposição básica do Naive Bayes é assumir que as features sejam independêntes entre si, o que não é\n",
    "necessariamente assumido no modelo de Gaussiana Multivariada.\n",
    "\n",
    "### Questão 3.4\n",
    "Temos que a likelihood é: \n",
    "$$\\mathcal{L}(\\theta \\mid \\boldsymbol{x}, y=c) = P(\\boldsymbol{x}, y=c \\mid \\theta) \\propto P(\\boldsymbol{x} \\mid y=c) P(y=c \\mid \\theta)$$\n",
    "Pela independência das features:\n",
    "$$\\mathcal{L}(\\theta \\mid \\boldsymbol{x}, y=c) = P(y=c \\mid \\theta) \\prod_{i=1}^{D} P(x_i \\mid y=c, \\theta)$$\n",
    "Aplicando log:\n",
    "$$log \\mathcal{L}(\\theta \\mid \\boldsymbol{x}, y=c) = log(P(y=c \\mid \\theta)) + \\sum_{i=1}^{D} log(P(x_i \\mid y=c, \\theta))$$\n",
    "Para obter os parâmetros otimizados, derivamos em relação a cada parâmetro e igualamos a 0. Como temos um Naive Bayes, os resultados serão:\n",
    "\n",
    "![title](Screenshot%20from%202017-11-16%2006-49-04.png)\n",
    "![title](Screenshot%20from%202017-11-16%2006-48-51.png)\n",
    "![title](Screenshot%20from%202017-11-16%2006-48-36.png)\n",
    "Onde k representa o parâmetro da késima classe.\n",
    "\n",
    "Já calculamos os parâmetros $ \\mu_k, \\Sigma_k$ na questão 3.1, somente restando $ \\pi_k $:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingGroups = {}\n",
    "trainingGroups['18_40'] = train.loc[(train['IDADE'] > 18) & (train['IDADE'] <= 40)][['Carga_Final','VO2_medido_máximo']]\n",
    "trainingGroups['40_60'] = train.loc[(train['IDADE'] > 40) & (train['IDADE'] <= 60)][['Carga_Final','VO2_medido_máximo']]\n",
    "trainingGroups['60'] = train.loc[(train['IDADE'] >= 60)][['Carga_Final','VO2_medido_máximo']]\n",
    "\n",
    "totalNumberOfSamples = 1000\n",
    "for group in groups:\n",
    "    params[group]['pi'] = len(trainingGroups[group])/totalNumberOfSamples\n",
    "    print('O pi, \"representatividade\", do grupo ' + group + ' é ' + str(params[group]['pi']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayesClassify(x, params):\n",
    "    probabilities = {}\n",
    "    for someClass in params:\n",
    "        parametersOfClass = params[someClass]\n",
    "        probabilities[someClass] = multivariate_normal.pdf(\n",
    "            x,\n",
    "            mean = [\n",
    "                parametersOfClass['mean_carga'],\n",
    "                parametersOfClass['mean_vo2']\n",
    "            ],\n",
    "            cov = parametersOfClass['cov']\n",
    "        )\n",
    "    \n",
    "    classPrediction = []\n",
    "    for i in range(len(x)):\n",
    "        maxProbability = max(\n",
    "            probabilities['18_40'][i],\n",
    "            probabilities['40_60'][i],\n",
    "            probabilities['60'][i],\n",
    "        )\n",
    "        for someClass in params:\n",
    "            if(probabilities[someClass][i] == maxProbability):\n",
    "                classPrediction.append(someClass)\n",
    "    \n",
    "    return classPrediction\n",
    "\n",
    "predictions = naiveBayesClassify(\n",
    "    test[['Carga_Final','VO2_medido_máximo']],\n",
    "    params\n",
    ")\n",
    "\n",
    "testAges = test[['IDADE']]\n",
    "errors = []\n",
    "i = 0\n",
    "for index, row in testAges.iterrows():\n",
    "    if(predictions[i] == '18_40'):\n",
    "        if(int(row[0]) < 18 or int(row[0]) > 40):\n",
    "            errors.append(predictions[i] + ' ' + str(int(row[0])))\n",
    "    elif(predictions[i] == '40_60'):\n",
    "        if(int(row[0]) < 40 or int(row[0]) > 60):\n",
    "            errors.append(predictions[i] + ' ' + str(int(row[0])))\n",
    "    elif(predictions[i] == '60'):\n",
    "        if(int(row[0]) < 60):\n",
    "            errors.append(predictions[i] + ' ' + str(int(row[0])))\n",
    "    i += 1\n",
    "print('Foram encontrados ' + str(len(errors)) + ' erros de previsão, ou ' + str(len(errors)*100/172) + '% de erro')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sim, conseguimos prever o restante a faixa etária dos dados de teste. A idéia é verificar \"em qual faixa etária o dado melhor se encaixa\". Para cada classe, verificaremos a probabilidade (PDF) dos dados serem gerados por ela, e quem tiver maior probabilidade será a classe do dado.\n",
    "![title](Screenshot%20from%202017-11-16%2008-36-19.png)\n",
    "\n",
    "### Questão 3.6\n",
    "Somente com as Gaussianas não seria possível. Precisamos de um método para determinar \"a qual Gaussiana o dado pertence\". Neste caso, o Naive Bayes desempenha exatamente esta função. Outra possibilidade seria usar o Mixture Model, que teria uma abordagem mais probabilistica e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import mixture\n",
    "\n",
    "df = train[['IDADE','Peso','Carga_Final','VO2_medido_máximo']]\n",
    "\n",
    "gmm = mixture.GaussianMixture(n_components=3)\n",
    "gmm.fit(np.array(df))\n",
    "labels = gmm.predict(np.array(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O gráfico abaixo mostra a relação entre Idade e Peso, sinalizando com cores diferentes pontos que forama tribuídos para gaussianas distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.array(test)[:, 0], np.array(test)[:, 1], c=labels, s=40, cmap='viridis');\n",
    "plt.xlabel(\"IDADE\")\n",
    "plt.ylabel(\"Peso\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2\n",
    "\n",
    "\n",
    "Para encontrar os parâmetros do modelo é utilizado o algoritmo de **Expectation Maximixation**. Esse algoritmo funciona através das seguintes etapas:\n",
    "s\n",
    "1. **Passo 1:** Inicializa a mistura de gaussianas com parâmetros ¨chutados¨ *(variâncias e médias)*\n",
    "2. **Passo 2:** *(E-Step)* Estima os valores das probabilidades a priori (pi) com base nos parâmetros atuais\n",
    "3. **Passo 3:** *(M-Step)* Estima novos parâmetros para o modelo com base nas probabilidades a priori e nos parâmetros atuais. São estimadas então novas médias e variâncias para as Gaussianas\n",
    "\n",
    "Esse algoritmo então itera até convergir para um mínimo local, sendo que em cada uma de suas iterações o log likelihood aumenta.\n",
    "\n",
    "A equação principal utilizada é:\n",
    "\n",
    "$$ \\begin{equation}\n",
    "\\begin{split}\n",
    "-\\Sigma^N_{n=1}\\frac{\\pi_k\\mathcal{N}(x_n|\\mu_k,\\Sigma_k)}{\\Sigma^K_{j=1}\\pi_j\n",
    "\\mathcal{N}(x_n|\\mu_j,\\Sigma_j)}\\Sigma_k(x_n-\\mu_k) =&& 0\\\\\n",
    "\\end{split}\n",
    "\\end{equation}$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
